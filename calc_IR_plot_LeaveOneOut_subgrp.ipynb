{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr,spearmanr, ttest_ind, ttest_rel, mannwhitneyu, shapiro, wilcoxon\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore a warning related to tsplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACPU\n",
      "ADHD-DUB1\n",
      "ADHD WUE\n",
      "ADHD_Rubia1\n",
      "ADHD200_KKI\n",
      "ADHD200_NYU\n",
      "ADHD200_OHSU\n",
      "ADHD200_Peking\n",
      "ADHDKonrad\n",
      "Bergen_adultADHD\n",
      "Bergen_SVG\n",
      "CAPS_UZH\n",
      "DAT_london\n",
      "Dundee\n",
      "Hartford_Olin\n",
      "IMpACT_NL\n",
      "MGH_ADHD\n",
      "MTA\n",
      "NeuroImage_ADAM\n",
      "NeuroImage_NIJM\n",
      "NICAP\n",
      "NICHE\n",
      "NIH\n",
      "NYU ADHD\n",
      "OHSU\n",
      "UAB-ADHD\n",
      "UCHZ\n",
      "HUBIN_KASP\n",
      "TOP15T\n",
      "TOP3T_0\n",
      "TOP3T_GE750\n",
      "Anna\n",
      "AnneU\n",
      "BILGIN\n",
      "CAMH_ASD\n",
      "Christoph\n",
      "ClarissaBr\n",
      "Colm_UCSF\n",
      "ClinG_sample\n",
      "HMS_sample\n",
      "EstherCOBRE\n",
      "EstherMCIC\n",
      "FIDMAG\n",
      "GEB\n",
      "GloriaBPSydney\n",
      "JPCapeTown\n",
      "Malt\n",
      "MatthewSacchet\n",
      "MDD_Ilya\n",
      "MichelleLBC\n",
      "ASY_results_FOR2107\n",
      "ASY_results_MuensterCohort\n",
      "NESDA\n",
      "NeuroIMAGE\n",
      "NicolaMAS\n",
      "NicolaOATS\n",
      "NORM_Moscow\n",
      "NUIG\n",
      "01_Cheng_1.5T\n",
      "01_Cheng_3T\n",
      "02_Heuvel_1.5T\n",
      "02_Heuvel_3T\n",
      "03_Huyser\n",
      "04_Mataix_Cols\n",
      "OXUK\n",
      "GRADUAL\n",
      "OLDERS\n",
      "Quinn\n",
      "SaoPaulo1\n",
      "SaoPaulo3\n",
      "SaudEPIGEN\n",
      "SHIP-2\n",
      "SHIP-TREND-0\n",
      "StenerEOP\n",
      "UMCG_sample_groenewold\n",
      "1.5T_Adults_Lateralization\n",
      "3T_Adults_Lateralization\n",
      "3T_Child_Adolescent_Lateralization\n",
      "Cousijn\n",
      "DStein\n",
      "EStein\n",
      "Foxe\n",
      "Garavan\n",
      "London\n",
      "Luijten\n",
      "Momenan\n",
      "Orr\n",
      "Ozlem\n",
      "Paulus\n",
      "Schmaal\n",
      "Sinha\n",
      "Sjoerds\n",
      "VanHolst\n",
      "Yucel\n",
      "Kwon_3T\n",
      "KwonNMC_15T\n",
      "KwonSNU_15T\n"
     ]
    }
   ],
   "source": [
    "# construct the matrix for result consistency between single dataset and the meta results with all the other datasets.\n",
    "dataset_info_file = './doc/dataset_info.csv'\n",
    "dataset_info = pd.read_csv(dataset_info_file)\n",
    "#dataset_info = dataset_info[dataset_info['ScannerField0']=='1.5'] # 1.5/3\n",
    "#folder_str = 'Scanner3'\n",
    "#folder_str = 'Scanner1.5'\n",
    "#dataset_info = dataset_info[dataset_info['AgeMax']<=18]\n",
    "#folder_str = 'Child'\n",
    "#dataset_info = dataset_info[dataset_info['AgeMin']>18]\n",
    "#folder_str = 'Adult'\n",
    "dataset_info = dataset_info[~dataset_info['Dataset'].isin(['BIG', 'QTIM'])] # check results after exluding the largest two datasets\n",
    "folder_str = 'exclBIGQTIM'\n",
    "\n",
    "pthr_single = 0.05 # significance threshold\n",
    "pthr = 0.05 # significance threshold for meta\n",
    "#pthr = 0.05/70.0# meta threshold when considering multiple testing correction\n",
    "\n",
    "dataset_by_region_mat = np.zeros((len(dataset_info['Dataset']),70)) \n",
    "# 1 for the same results (sig. & same direction, or all not sig.), otherwise 0 \n",
    "\n",
    "dataset_by_region_mat2 = np.zeros((len(dataset_info['Dataset']),70)) \n",
    "# 1 for the same results (sig. & same direction), otherwise 0 \n",
    "\n",
    "for j, dataset in enumerate(dataset_info['Dataset']):\n",
    "    print(dataset)\n",
    "    # read the meta results while excluding that dataset\n",
    "    #meta_f = u'./meta/sum_asy_meta_excl_'+dataset+'.csv'\n",
    "    meta_f = u'./meta_subgrp/'+folder_str+'/sum_asy_meta_excl_'+dataset+'.csv'\n",
    "    \n",
    "    meta_dat = pd.read_csv(meta_f)\n",
    "    meta_dat[u'estimate_abs'] = np.abs(meta_dat[u'estimate'])\n",
    "    \n",
    "    csv_list =  meta_dat[u'Region']\n",
    "    for i, csv_f in enumerate(csv_list):\n",
    "        meta_z = meta_dat[u'zval'][i] # meta effect for that region\n",
    "        meta_p = meta_dat[u'pval'][i] # meta effect for that region\n",
    "        csv_dat = pd.read_csv(os.path.join('./data/',csv_f))\n",
    "        \n",
    "        csv_dat = csv_dat[csv_dat['Dataset']==dataset]\n",
    "        #print(meta_p, meta_z, csv_dat[u'p'].values[0], csv_dat[u't'].values[0])\n",
    "        if (meta_p <=pthr) and (csv_dat[u'p'].values[0]<=pthr_single) and ((csv_dat[u't'].values[0]*meta_z)>0)==True: \n",
    "            # significant & same direction\n",
    "            dataset_by_region_mat[j,i] = 1\n",
    "        elif (meta_p >pthr) and (csv_dat[u'p'].values[0]>pthr_single): # both not sig.\n",
    "            dataset_by_region_mat[j,i] = 1\n",
    "        else: # meta_p > pthr for ~false positive\n",
    "            dataset_by_region_mat[j,i] = 0 \n",
    "            \n",
    "        if (meta_p <=pthr) and (csv_dat[u'p'].values[0]<=pthr_single) and ((csv_dat[u't'].values[0]*meta_z)>0)==True: \n",
    "            # significant & same direction\n",
    "            dataset_by_region_mat2[j,i] = 1            \n",
    "        else: # meta_p > pthr for ~false positive\n",
    "            dataset_by_region_mat2[j,i] = 0\n",
    "\n",
    "#plt.imshow(dataset_by_region_mat)\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(dataset_by_region_mat2)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Overall---\n",
      "Ovall mean and sd, across 70 region effects\n",
      " 0.6265095729013253 0.23330599711114683\n",
      "Max, and min:\n",
      " 0.1958762886597938 0.9690721649484536\n",
      "---Total, and Regional---\n",
      "Total surface asymmetry 0.6597938144329897\n",
      "Average thickness asymmetry 0.35051546391752575\n"
     ]
    }
   ],
   "source": [
    "# characterize the reproducibility\n",
    "#dataset_info_file = './doc/dataset_info.csv'\n",
    "#dataset_info = pd.read_csv(dataset_info_file)\n",
    "\n",
    "print('---Overall---')\n",
    "print('Ovall mean and sd, across 70 region effects\\n', \n",
    "      dataset_by_region_mat.mean(axis=0).mean(), \n",
    "      dataset_by_region_mat.mean(axis=0).std())\n",
    "print('Max, and min:\\n',\n",
    "      dataset_by_region_mat.mean(axis=0).min(),\n",
    "      dataset_by_region_mat.mean(axis=0).max())\n",
    "print('---Total, and Regional---')\n",
    "print('Total surface asymmetry',dataset_by_region_mat[:,0].mean(axis=0).mean())\n",
    "print('Average thickness asymmetry',dataset_by_region_mat[:,1].mean(axis=0).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
